{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87a8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Direction</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>하락형</td>\n",
       "      <td>D1</td>\n",
       "      <td>D1</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>상승형</td>\n",
       "      <td>U1</td>\n",
       "      <td>U1</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>하락형</td>\n",
       "      <td>D5</td>\n",
       "      <td>D6</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>하락형</td>\n",
       "      <td>U8</td>\n",
       "      <td>D10</td>\n",
       "      <td>상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>상승형</td>\n",
       "      <td>E2</td>\n",
       "      <td>U2</td>\n",
       "      <td>하락</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Direction Col1 Col2 Result\n",
       "0       하락형   D1   D1     하락\n",
       "1       상승형   U1   U1     상승\n",
       "2       하락형   D5   D6     하락\n",
       "3       하락형   U8  D10     상승\n",
       "4       상승형   E2   U2     하락"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "conn = pymysql.connect(host='localhost', port = 3306, user='root', \n",
    "            password='1234', db='INVESTAR', charset='utf8')\n",
    "sql = \"SELECT * FROM test_data\"\n",
    "df = pd.read_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c20df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "보합    7105\n",
       "상승    4957\n",
       "하락    4560\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(['Result'], axis = 1)\n",
    "x = pd.get_dummies(x, drop_first = True)\n",
    "y = df['Result']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b16ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle=True,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd2c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49297971918876754\n"
     ]
    }
   ],
   "source": [
    "# SVM - linearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "C = 0.1\n",
    "lsvc_clf = LinearSVC(C=C, max_iter = 10000, multi_class = 'ovr')\n",
    "lsvc_clf.fit(x_train,y_train)\n",
    "y_pred = lsvc_clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d927cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48798751950078\n"
     ]
    }
   ],
   "source": [
    "# svm - svc\n",
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(kernel = 'rbf', probability = True)\n",
    "svc_clf.fit(x_train,y_train)\n",
    "y_pred = svc_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e3bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4237129485179407\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9db3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "최고 평균 정확도 수치 : 0.493119\n",
      "최적 하이퍼 파라미터 : {'max_depth': 12, 'min_samples_split': 16}\n",
      "결정트리 예측 정확도 : 0.4758\n",
      "0.47578947368421054\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "params = {'max_depth' : [6,8,10,12,16,20,24], 'min_samples_split' : [16, 24]}\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1)\n",
    "grid_cv.fit(x_train, y_train)\n",
    "print('최고 평균 정확도 수치 : {0:4f}'.format(grid_cv.best_score_))\n",
    "print('최적 하이퍼 파라미터 :', grid_cv.best_params_)\n",
    "\n",
    "best_df_clf = grid_cv.best_estimator_\n",
    "pred1 = best_df_clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred1)\n",
    "print('결정트리 예측 정확도 : {:.4f}'.format(accuracy))\n",
    "dt_clf = DecisionTreeClassifier(max_depth = 12, min_samples_split = 16)\n",
    "dt_clf.fit(x_train, y_train)\n",
    "pred = dt_clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b61a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.48798751950078\n",
      "SVC 0.48798751950078\n",
      "VotingClassifier 0.48985959438377535\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "rnd_clf = RandomForestClassifier()\n",
    "voting_clf = VotingClassifier(estimators = [('rf', rnd_clf), ('svc', svc_clf)],\n",
    "                             voting = 'soft')\n",
    "voting_clf.fit(x_train, y_train)\n",
    "for clf in (rnd_clf, svc_clf, voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43941618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4901716068642746\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500,\n",
    "                           max_samples = 10000, bootstrap=True, n_jobs=-1, oob_score = True)\n",
    "bag_clf.fit(x_train, y_train)\n",
    "y_pred = bag_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf41cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49297971918876754\n"
     ]
    }
   ],
   "source": [
    "# Pasting\n",
    "past_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500,\n",
    "                           max_samples = 300, bootstrap=False, n_jobs=-1)\n",
    "past_clf.fit(x_train, y_train)\n",
    "y_pred = past_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e67024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49890795631825274\n"
     ]
    }
   ],
   "source": [
    "# adaboost boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 2), n_estimators = 200,\n",
    "                           algorithm='SAMME.R', learning_rate = 0.5)\n",
    "ada_clf.fit(x_train, y_train)\n",
    "y_pred = ada_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a680673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.06610\n",
      "[1]\tvalidation_0-mlogloss:1.04581\n",
      "[2]\tvalidation_0-mlogloss:1.03179\n",
      "[3]\tvalidation_0-mlogloss:1.02254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82106\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\tvalidation_0-mlogloss:1.01569\n",
      "[5]\tvalidation_0-mlogloss:1.01086\n",
      "[6]\tvalidation_0-mlogloss:1.00763\n",
      "[7]\tvalidation_0-mlogloss:1.00514\n",
      "[8]\tvalidation_0-mlogloss:1.00322\n",
      "[9]\tvalidation_0-mlogloss:1.00215\n",
      "[10]\tvalidation_0-mlogloss:1.00089\n",
      "[11]\tvalidation_0-mlogloss:1.00007\n",
      "[12]\tvalidation_0-mlogloss:0.99911\n",
      "[13]\tvalidation_0-mlogloss:0.99825\n",
      "[14]\tvalidation_0-mlogloss:0.99757\n",
      "[15]\tvalidation_0-mlogloss:0.99713\n",
      "[16]\tvalidation_0-mlogloss:0.99659\n",
      "[17]\tvalidation_0-mlogloss:0.99643\n",
      "[18]\tvalidation_0-mlogloss:0.99615\n",
      "[19]\tvalidation_0-mlogloss:0.99554\n",
      "[20]\tvalidation_0-mlogloss:0.99532\n",
      "[21]\tvalidation_0-mlogloss:0.99540\n",
      "[22]\tvalidation_0-mlogloss:0.99487\n",
      "[23]\tvalidation_0-mlogloss:0.99474\n",
      "[24]\tvalidation_0-mlogloss:0.99485\n",
      "[25]\tvalidation_0-mlogloss:0.99469\n",
      "[26]\tvalidation_0-mlogloss:0.99456\n",
      "[27]\tvalidation_0-mlogloss:0.99455\n",
      "[28]\tvalidation_0-mlogloss:0.99447\n",
      "[29]\tvalidation_0-mlogloss:0.99458\n",
      "[30]\tvalidation_0-mlogloss:0.99438\n",
      "[31]\tvalidation_0-mlogloss:0.99425\n",
      "[32]\tvalidation_0-mlogloss:0.99438\n",
      "0.49173166926677064\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting\n",
    "import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier()\n",
    "xgb_clf.fit(x_train, y_train, eval_set = [(x_test, y_test)], early_stopping_rounds=2)\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2b9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVD 정확도 : 0.47729323308270677\n",
      "SVC 정확도 : 0.48\n",
      "KNN 정확도 : 0.4336842105263158\n",
      "Decision Tree : 0.4724812030075188\n",
      "Voting\n",
      "  RandomForestClassifier 정확도 : 0.4733834586466165\n",
      "  SVC 정확도 : 0.48\n",
      "  VotingClassifier 정확도 : 0.47458646616541356\n",
      "Bagging : 0.47398496240601506\n",
      "Pasting : 0.4766917293233083\n",
      "adaboost boosting : 0.4781954887218045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# SVM - linearSVC\n",
    "C = 0.1\n",
    "lsvc_clf = LinearSVC(C=C, max_iter = 10000, multi_class = 'ovr')\n",
    "lsvc_clf.fit(x_train,y_train)\n",
    "y_pred = lsvc_clf.predict(x_test)\n",
    "print(f'LinearSVD 정확도 : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# svm - svc\n",
    "svc_clf = SVC(kernel = 'rbf', probability = True)\n",
    "svc_clf.fit(x_train,y_train)\n",
    "y_pred = svc_clf.predict(x_test)\n",
    "print(f'SVC 정확도 : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(f'KNN 정확도 : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=156)\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(f'Decision Tree : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# VotingClassifier\n",
    "print('Voting')\n",
    "rnd_clf = RandomForestClassifier()\n",
    "voting_clf = VotingClassifier(estimators = [('rf', rnd_clf), ('svc', svc_clf)],\n",
    "                             voting = 'soft')\n",
    "voting_clf.fit(x_train, y_train)\n",
    "for clf in (rnd_clf, svc_clf, voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(' ',clf.__class__.__name__,'정확도 :', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "# Bagging\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500,\n",
    "                           max_samples = 10000, bootstrap=True, n_jobs=-1, oob_score = True)\n",
    "bag_clf.fit(x_train, y_train)\n",
    "y_pred = bag_clf.predict(x_test)\n",
    "print(f'Bagging : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# Pasting\n",
    "past_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500,\n",
    "                           max_samples = 300, bootstrap=False, n_jobs=-1)\n",
    "past_clf.fit(x_train, y_train)\n",
    "y_pred = past_clf.predict(x_test)\n",
    "print(f'Pasting : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# adaboost boosting\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 2), n_estimators = 200,\n",
    "                           algorithm='SAMME.R', learning_rate = 0.5)\n",
    "ada_clf.fit(x_train, y_train)\n",
    "y_pred = ada_clf.predict(x_test)\n",
    "print(f'adaboost boosting : {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d4448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
